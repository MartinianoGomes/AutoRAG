# üöÄ AutoRAG - Guia Completo de Uso e Teste

> **AutoRAG** √© uma ferramenta de AutoML para encontrar automaticamente o melhor pipeline RAG para seus dados.

---

## üìã √çndice

1. [Instala√ß√£o](#instala√ß√£o)
2. [Teste R√°pido (5 minutos)](#teste-r√°pido-5-minutos)
3. [Teste com Modelos Locais](#teste-com-modelos-locais)
4. [Estrutura dos Dados](#estrutura-dos-dados)
5. [Configura√ß√£o YAML](#configura√ß√£o-yaml)
6. [Comandos CLI](#comandos-cli)
7. [M√©tricas Dispon√≠veis](#m√©tricas-dispon√≠veis)
8. [M√≥dulos Dispon√≠veis](#m√≥dulos-dispon√≠veis)
9. [Criando Seus Pr√≥prios Dados](#criando-seus-pr√≥prios-dados)
10. [Resultados de Exemplo](#resultados-de-exemplo)

---

## Instala√ß√£o

### Pr√©-requisitos
- Python 3.10+ (3.12 recomendado)
- pip ou UV (gerenciador de pacotes r√°pido)

### Instala√ß√£o no Windows

```powershell
# 1. Navegar para o diret√≥rio do projeto
cd C:\Users\martinianogomes\OneDrive\Documentos\Projetos\AutoRAG

# 2. Criar ambiente virtual
python -m venv .venv

# 3. Ativar ambiente (PowerShell)
.\.venv\Scripts\Activate.ps1

# Ou no CMD:
# .venv\Scripts\activate.bat

# Ou no Git Bash:
# source .venv/Scripts/activate

# 4. Instalar AutoRAG com todas as depend√™ncias (pode levar 15-30 min)
pip install -e ".[all]" --timeout 3600

# 5. (Opcional) Instalar suporte a modelos locais
pip install torch sentence-transformers llama-index-embeddings-huggingface
```

### Instala√ß√£o no Linux

```bash
# 1. Navegar para o diret√≥rio do projeto
cd /home/martinianogomes/Documentos/Projetos/Academico/TCC/AutoRAG

# 2. Criar ambiente virtual
python -m venv .venv

# 3. Ativar ambiente
source .venv/bin/activate

# 4. Instalar AutoRAG b√°sico
pip install -e ".[all]" --timeout 3600

# 5. (Opcional) Instalar suporte a modelos locais
pip install torch sentence-transformers llama-index-embeddings-huggingface
```

### Verificar Instala√ß√£o

```bash
# Windows (Git Bash): source .venv/Scripts/activate
# Windows (PowerShell): .\.venv\Scripts\Activate.ps1
# Linux: source .venv/bin/activate

autorag --help
```

---

## Teste R√°pido (5 minutos)

### 1. Teste mais simples (apenas BM25, sem API keys)

```bash
cd /home/martinianogomes/Documentos/Projetos/Academico/TCC/AutoRAG
source .venv/bin/activate

# Executar avalia√ß√£o com dados de exemplo
autorag evaluate \
    --config tutorial/config_simples.yaml \
    --qa_data_path tests/resources/qa_data_sample.parquet \
    --corpus_data_path tests/resources/corpus_data_sample.parquet \
    --project_dir tutorial/meu_teste
```

### 2. Ver resultados

```bash
# Via terminal
cat tutorial/meu_teste/0/retrieve_node_line/lexical_retrieval/summary.csv

# Via Dashboard (interface visual)
autorag dashboard --trial_dir tutorial/meu_teste/0 --port 7690
# Acesse: http://localhost:7690
```

---

## Teste com Modelos Locais

### Configura√ß√£o para Vector DB em Mem√≥ria (sem API keys)

O arquivo `tutorial/config_local.yaml` j√° est√° configurado para usar:
- **BM25**: Busca l√©xica
- **ChromaDB em mem√≥ria**: Busca sem√¢ntica com modelo local (all-mpnet-base-v2)
- **H√≠brido**: Combina√ß√£o de ambos (RRF e CC)

### Executar Teste Completo

```bash
cd /home/martinianogomes/Documentos/Projetos/Academico/TCC/AutoRAG
source .venv/bin/activate

# Executar avalia√ß√£o com modelos locais
autorag evaluate \
    --config tutorial/config_local.yaml \
    --qa_data_path tests/resources/qa_data_sample.parquet \
    --corpus_data_path tests/resources/corpus_data_sample.parquet \
    --project_dir tutorial/projeto_local
```

### Comparar Resultados

```bash
# Ver resultados de cada m√©todo
cat tutorial/projeto_local/0/retrieve_node_line/lexical_retrieval/summary.csv
cat tutorial/projeto_local/0/retrieve_node_line/semantic_retrieval/summary.csv
cat tutorial/projeto_local/0/retrieve_node_line/hybrid_retrieval/summary.csv
```

### Abrir Dashboard

```bash
autorag dashboard --trial_dir tutorial/projeto_local/0 --port 7690
```

---

## Estrutura dos Dados

### QA Dataset (qa.parquet)

| Coluna | Tipo | Descri√ß√£o | Exemplo |
|--------|------|-----------|---------|
| `qid` | str | ID √∫nico da pergunta | "q_001" |
| `query` | str | A pergunta | "O que √© Python?" |
| `retrieval_gt` | List[List[str]] | IDs dos documentos relevantes | [["doc_001"]] |
| `generation_gt` | List[str] | Respostas esperadas | ["Python √© uma linguagem..."] |

### Corpus Dataset (corpus.parquet)

| Coluna | Tipo | Descri√ß√£o | Exemplo |
|--------|------|-----------|---------|
| `doc_id` | str | ID √∫nico do documento | "doc_001" |
| `contents` | str | Conte√∫do textual | "Python √© uma linguagem de programa√ß√£o..." |
| `metadata` | dict | Metadados (opcional) | {"source": "wikipedia"} |

---

## Configura√ß√£o YAML

### Configura√ß√£o M√≠nima (BM25 apenas)

```yaml
# config_simples.yaml
node_lines:
  - node_line_name: retrieve_node_line
    nodes:
      - node_type: lexical_retrieval
        strategy:
          metrics: [retrieval_f1, retrieval_recall, retrieval_precision]
        top_k: 3
        modules:
          - module_type: bm25
            bm25_tokenizer: [porter_stemmer, space]
```

### Configura√ß√£o com Vector DB Local (em mem√≥ria)

```yaml
# config_local.yaml
vectordb:
  - name: chroma_local
    db_type: chroma
    client_type: ephemeral  # Em mem√≥ria - n√£o persiste
    embedding_model: huggingface_all_mpnet_base_v2  # Modelo LOCAL
    collection_name: memoria_local
    embedding_batch: 50

node_lines:
  - node_line_name: retrieve_node_line
    nodes:
      # 1. Busca L√©xica
      - node_type: lexical_retrieval
        strategy:
          metrics: [retrieval_f1, retrieval_recall, retrieval_precision, retrieval_ndcg]
        top_k: 5
        modules:
          - module_type: bm25
            bm25_tokenizer: [porter_stemmer, space]

      # 2. Busca Sem√¢ntica
      - node_type: semantic_retrieval
        strategy:
          metrics: [retrieval_f1, retrieval_recall, retrieval_precision, retrieval_ndcg]
        top_k: 5
        modules:
          - module_type: vectordb
            vectordb: chroma_local

      # 3. Busca H√≠brida
      - node_type: hybrid_retrieval
        strategy:
          metrics: [retrieval_f1, retrieval_recall, retrieval_precision, retrieval_ndcg]
        top_k: 5
        modules:
          - module_type: hybrid_rrf
            weight_range: (4, 80)
          - module_type: hybrid_cc
            normalize_method: [mm, tmm, z]
            weight_range: (0.0, 1.0)
            test_weight_size: 21
```

### Configura√ß√£o com OpenAI (requer API key)

```yaml
# Requer: export OPENAI_API_KEY="sk-sua-chave"
vectordb:
  - name: chroma_openai
    db_type: chroma
    client_type: ephemeral
    embedding_model: openai_embed_3_small
    collection_name: openai_collection

node_lines:
  - node_line_name: retrieve_node_line
    nodes:
      - node_type: semantic_retrieval
        strategy:
          metrics: [retrieval_f1, retrieval_recall]
        top_k: 5
        modules:
          - module_type: vectordb
            vectordb: chroma_openai
```

---

## Comandos CLI

### Comandos Principais

```bash
# Ver ajuda
autorag --help

# Validar configura√ß√£o (sem executar)
autorag validate \
    --config config.yaml \
    --qa_data_path qa.parquet \
    --corpus_data_path corpus.parquet

# Executar avalia√ß√£o completa
autorag evaluate \
    --config config.yaml \
    --qa_data_path qa.parquet \
    --corpus_data_path corpus.parquet \
    --project_dir ./projeto

# Pular valida√ß√£o (mais r√°pido)
autorag evaluate \
    --config config.yaml \
    --qa_data_path qa.parquet \
    --corpus_data_path corpus.parquet \
    --project_dir ./projeto \
    --skip_validation true
```

### Visualiza√ß√£o e Deploy

```bash
# Dashboard interativo
autorag dashboard --trial_dir ./projeto/0 --port 7690

# API Server REST
autorag run_api --trial_dir ./projeto/0 --port 8000

# Interface Web (Streamlit)
autorag run_web --trial_path ./projeto/0

# Extrair melhor configura√ß√£o
autorag extract_best_config --trial_path ./projeto/0 --output_path best_config.yaml
```

---

## M√©tricas Dispon√≠veis

### M√©tricas de Retrieval

| M√©trica | Descri√ß√£o | Quando usar |
|---------|-----------|-------------|
| `retrieval_f1` | F1 Score (harm√¥nica de precision e recall) | M√©trica balanceada geral |
| `retrieval_recall` | Propor√ß√£o de docs relevantes encontrados | Quando n√£o pode perder nenhum doc |
| `retrieval_precision` | Propor√ß√£o de docs retornados que s√£o relevantes | Quando quer resultados precisos |
| `retrieval_ndcg` | Normalized Discounted Cumulative Gain | Avalia a ordem do ranking |
| `retrieval_mrr` | Mean Reciprocal Rank | Posi√ß√£o do primeiro doc relevante |
| `retrieval_map` | Mean Average Precision | M√©dia da precis√£o em cada posi√ß√£o |

### M√©tricas de Gera√ß√£o

| M√©trica | Descri√ß√£o |
|---------|-----------|
| `bleu` | BLEU Score - correspond√™ncia de n-gramas |
| `meteor` | METEOR Score - sin√¥nimos e stemming |
| `rouge` | ROUGE Score - sobreposi√ß√£o de sequ√™ncias |
| `sem_score` | Similaridade sem√¢ntica |
| `bert_score` | BERTScore - similaridade contextual |
| `g_eval` | Avalia√ß√£o por GPT |

---

## M√≥dulos Dispon√≠veis

### Retrieval

| M√≥dulo | Tipo | Descri√ß√£o | Requer API? |
|--------|------|-----------|-------------|
| `bm25` | L√©xico | BM25 com diferentes tokenizadores | ‚ùå |
| `vectordb` | Sem√¢ntico | Busca por embeddings | Depende do modelo |
| `hybrid_rrf` | H√≠brido | Reciprocal Rank Fusion | Depende |
| `hybrid_cc` | H√≠brido | Convex Combination | Depende |

### Modelos de Embedding

| Nome | Tipo | Descri√ß√£o |
|------|------|-----------|
| `huggingface_all_mpnet_base_v2` | Local | Sentence Transformers (768 dim) |
| `huggingface_baai_bge_small` | Local | BGE Small (384 dim) |
| `huggingface_bge_m3` | Local | BGE M3 multilingual |
| `openai_embed_3_small` | API | OpenAI text-embedding-3-small |
| `openai_embed_3_large` | API | OpenAI text-embedding-3-large |
| `mock` | Teste | Embeddings aleat√≥rios (para teste) |

### Tokenizadores BM25

| Tokenizador | Descri√ß√£o |
|-------------|-----------|
| `porter_stemmer` | Stemmer Porter (ingl√™s) |
| `space` | Tokeniza√ß√£o por espa√ßo |
| `gpt2` | Tokenizador GPT-2 |
| `ko_kiwi` | Tokenizador coreano |

### Vector Databases

| DB | Tipo | Uso |
|----|------|-----|
| `chroma` (ephemeral) | Em mem√≥ria | Testes r√°pidos |
| `chroma` (persistent) | Em disco | Desenvolvimento |
| `milvus` | Servidor | Produ√ß√£o |
| `pinecone` | Cloud | Produ√ß√£o escal√°vel |
| `qdrant` | Servidor | Produ√ß√£o |
| `weaviate` | Servidor | Produ√ß√£o |

---

## Criando Seus Pr√≥prios Dados

### Exemplo Python

```python
import pandas as pd

# 1. CRIAR CORPUS (seus documentos)
corpus_data = [
    {
        "doc_id": "doc_001",
        "contents": "Python √© uma linguagem de programa√ß√£o de alto n√≠vel, interpretada e de prop√≥sito geral.",
        "metadata": {"source": "wikipedia", "topic": "programming"}
    },
    {
        "doc_id": "doc_002",
        "contents": "Machine Learning √© um subcampo da intelig√™ncia artificial que permite sistemas aprenderem com dados.",
        "metadata": {"source": "wikipedia", "topic": "ai"}
    },
    {
        "doc_id": "doc_003",
        "contents": "RAG (Retrieval-Augmented Generation) combina busca de documentos com gera√ß√£o de texto por LLMs.",
        "metadata": {"source": "paper", "topic": "nlp"}
    },
]
corpus_df = pd.DataFrame(corpus_data)
corpus_df.to_parquet("meu_corpus.parquet", index=False)

# 2. CRIAR QA DATASET (perguntas e respostas)
qa_data = [
    {
        "qid": "q_001",
        "query": "O que √© Python?",
        "retrieval_gt": [["doc_001"]],  # IDs dos docs relevantes
        "generation_gt": ["Python √© uma linguagem de programa√ß√£o de alto n√≠vel"]
    },
    {
        "qid": "q_002",
        "query": "O que √© Machine Learning?",
        "retrieval_gt": [["doc_002"]],
        "generation_gt": ["Machine Learning √© um subcampo da intelig√™ncia artificial"]
    },
    {
        "qid": "q_003",
        "query": "Como funciona RAG?",
        "retrieval_gt": [["doc_003"]],
        "generation_gt": ["RAG combina busca de documentos com gera√ß√£o de texto"]
    },
]
qa_df = pd.DataFrame(qa_data)
qa_df.to_parquet("meu_qa.parquet", index=False)

print("‚úÖ Dados criados!")
print(f"   Corpus: {len(corpus_df)} documentos")
print(f"   QA: {len(qa_df)} perguntas")
```

### Executar com Seus Dados

```bash
autorag evaluate \
    --config tutorial/config_local.yaml \
    --qa_data_path meu_qa.parquet \
    --corpus_data_path meu_corpus.parquet \
    --project_dir meu_projeto
```

---

## Resultados de Exemplo

### Compara√ß√£o: BM25 vs Sem√¢ntico vs H√≠brido

Resultados obtidos com os dados de exemplo (`tests/resources/`):

| M√©todo | F1 Score | Recall | Precision | NDCG |
|--------|----------|--------|-----------|------|
| **BM25 (porter_stemmer)** | 0.333 | 100% | 20% | **1.00** |
| **VectorDB (all-mpnet)** | 0.333 | 100% | 20% | 0.94 |
| **H√≠brido (CC)** | 0.333 | 100% | 20% | **1.00** |

### Interpreta√ß√£o

- **Recall 100%**: Todos os m√©todos encontram o documento relevante
- **NDCG**: BM25 e H√≠brido ordenam melhor o ranking (1.0 vs 0.94)
- **Conclus√£o**: Para este dataset, BM25 √© suficiente e mais eficiente

---

## Estrutura de Arquivos Gerados

Ap√≥s executar `autorag evaluate`:

```
projeto/
‚îú‚îÄ‚îÄ data/
‚îÇ   ‚îú‚îÄ‚îÄ qa.parquet           # C√≥pia dos dados QA
‚îÇ   ‚îî‚îÄ‚îÄ corpus.parquet       # C√≥pia do corpus
‚îú‚îÄ‚îÄ resources/
‚îÇ   ‚îú‚îÄ‚îÄ bm25_*.pkl           # √çndices BM25 
‚îÇ   ‚îî‚îÄ‚îÄ chroma/              # Vector DB (se persistente)
‚îú‚îÄ‚îÄ 0/                       # Trial 0
‚îÇ   ‚îú‚îÄ‚îÄ config.yaml          # Configura√ß√£o usada
‚îÇ   ‚îú‚îÄ‚îÄ summary.csv          # Resumo geral
‚îÇ   ‚îî‚îÄ‚îÄ retrieve_node_line/
‚îÇ       ‚îú‚îÄ‚îÄ summary.csv
‚îÇ       ‚îú‚îÄ‚îÄ lexical_retrieval/
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ summary.csv  # M√©tricas por m√≥dulo
‚îÇ       ‚îÇ   ‚îú‚îÄ‚îÄ 0.parquet    # Resultados m√≥dulo 0
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ best_0.parquet # Melhor resultado
‚îÇ       ‚îú‚îÄ‚îÄ semantic_retrieval/
‚îÇ       ‚îÇ   ‚îî‚îÄ‚îÄ ...
‚îÇ       ‚îî‚îÄ‚îÄ hybrid_retrieval/
‚îÇ           ‚îî‚îÄ‚îÄ ...
‚îî‚îÄ‚îÄ trial.json               # Metadados do trial
```

---

## Dicas e Troubleshooting

### Erros Comuns

| Erro | Causa | Solu√ß√£o |
|------|-------|---------|
| `Directory does not exist` | Caminho errado | Verifique o caminho com `ls` |
| `No module named torch` | PyTorch n√£o instalado | `uv pip install torch` |
| `OPENAI_API_KEY` | API key n√£o configurada | `export OPENAI_API_KEY="sk-..."` |

### Dicas de Performance

1. **Comece simples**: Use BM25 primeiro para validar seus dados
2. **top_k menor**: top_k=3 geralmente d√° melhor F1 que top_k=10
3. **Modelos locais**: Use `huggingface_all_mpnet_base_v2` para testes sem API
4. **Ephemeral vs Persistent**: Use `ephemeral` para testes r√°pidos

### Arquivos de Configura√ß√£o de Exemplo

| Arquivo | Descri√ß√£o |
|---------|-----------|
| `tutorial/config_simples.yaml` | Apenas BM25 |
| `tutorial/config_local.yaml` | BM25 + VectorDB local + H√≠brido |
| `tutorial/config_comparacao_bm25.yaml` | Compara√ß√£o de tokenizadores |
| `sample_config/rag/full.yaml` | Configura√ß√£o completa (todos m√≥dulos) |

---

## Links √öteis

- **Documenta√ß√£o oficial**: https://marker-inc-korea.github.io/AutoRAG/
- **GitHub**: https://github.com/Marker-Inc-Korea/AutoRAG
- **Colab Tutorial**: [Step 1: B√°sico](https://colab.research.google.com/drive/19OEQXO_pHN6gnn2WdfPd4hjnS-4GurVd)
